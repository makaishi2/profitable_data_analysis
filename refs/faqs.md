### FAQ

データサイエンティスト協会主催の講演会でいただいたご質問を中心に本書に関連するFAQをまとめました。

| ID   | 質問                                                         | 回答                                                         |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Q01  | Pythonを使って分析をしようと思います。     <br />その前に他社がPythonを使ってどんな分析をしたのか事例を知りたいのですが、調べる方法などありますでしょうか？     <br />特に、課題と分析手法と効果が分かれば嬉しいです | 書籍の4章から8章では、個別のビジネスケース、適用した分析手法、効果などのシナリオが一通り含まれているので、まずはこのシナリオを通しで読んでいただき、典型的パターンを理解するところから初めて下さい。      <br />Kaggle(英語)やsignate(日本語)などのサイトにアクセスするとより多くの活用事例のバリエーションを得られます     初級者はこれらのサイトの情報だけでは、特にビジネス観点の理解が難しい部分もありますが、そこは生成AIに教えてもらうといいかと思います |
| Q02  | 生成AIを利用することによってデータ分析におけるPythonやライブラリの記法・文法に関する習熟度への依存度が下がったと認識しています。     　<br />しかしプロンプトの生成やタスクに応じたプロンプトの分割、手順の生成にはどうしてもデータ分析の素養が求められるように思います。     　<br />上記を前提として2点質問がございます。     　<br />(Q002-1) 経験の浅いメンバーが生成AIを補助的に利用する時、社内やチームでどのようなレビュープロセスを用意すべきでしょうか。     　<br />(Q002-2) 未経験者が生成AIの誤りに気づきやすい状態を作る仕組みやプロセスはありますでしょうか? | (A02-1)講演でも話したとおり、これからの時代に一番重要なのは「問いを発する力」つまり「プロンプトを考える力」なのかと思います。      <br />なので、レビュープロセスでは、経験の浅いメンバーに「なぜこのプロンプトを出したのか」を説明してもらい、その正しさを有識者がチェックすると効率よくスキルを付けることができるかと思います。     <br />(A02-2)上記レビュープロセスの過程で、それぞれのAIの結果に対して都度「このAIの結果は正しいと思うか」を質問し、間違いがある場合は都度有識者がその具体的なところを指摘する対応をとってはいかがでしょうか。ちょうど、講演の最後のところで話した「AIのハルシネーション事例」の指摘を有識者が行うイメージです |
| Q03  | デモの冒頭で実施した、日本語ライブラリの導入に使ったファイルはオープンソースとして拾えるものですか?また、おすすめのものがありましたらURLなど教えていただけると嬉しいです。 | 実習で利用したjapanize_matplotlibはOSSとしてダウンロード可能なライプラリです。     <br />通常、Google Colabなどの環境から利用する場合は「!pip install  japanize_matplotlib」という呼び出し方で使えるのですが、 ChatGPTの仮想python環境では、インターネットに直接アクセスできないため、ライブラリをいったんwhl形式のローカルファイルにして、それをChatGPTにアップロードする方式をとります。このこと自体、ChatGPT利用のTipsになります。 |
| Q04  | デモの最初でインストールが必要とのことでしたが、何をどのようにインストールすればよろしいでしょうか。 | インストールが必要なのはグラフの日本語化表示をするためのinstall  japanize_matplotlibというライブラリです。      <br />ChatGPTを使う場合、デモでやったようにライブラリファイルを添付した上で、「グラフが文字化けしないよう、添付のライブラリを!pipコマンドで導入してください」というプロンプトを流すと、AIがPython仮想環境に対してライブラリのインストールをやってくれます |
| Q05  | 現在、「claude」という生成AIを使用しているのですが、やはりchatgptの方がいいのでしょうか。「claude」の方がレスポンスも早く正確な気がするのですが… | 現時点でclaudeそのものがPythonの仮想環境を持っていることはなさそうです。     <br />アカウントを作って即、データ分析ができるという点において、ChatGPT plusの方が初心者に向いていると思います。 |
| Q06  | GPTに複数のテキストファイルを読み込ませる時、どこに注意する必要がありますか？　それを処理する場合の注意点を教えてください。     アンケートなどの複数のテキストです。 | いったん、個別ファイルごとにアップして、整形や表にするなどの指示を出します。その後で複数のデータを組み合わせる指示を出すと、効率よく分析が可能かと思います。 |
| Q07  | コードは理解できるレベルの学習で、覚える必要性は高くないという認識でよろしいでしょうか | 自分でゼロから作る必要はなくなりました(英作文はやらなくていい)。しかし、まだAIは間違えることがあるので、AIのコードが正しいかを確認できるスキルは必要です。これは「英文解釈ができる力」と例えることができると思います。 |
| Q08  | 文系DX社員です。     <br />いつもPythonなど自己学習する前に環境設定で躓くことが多いです。     <br />先のデモの冒頭であったような、【こうゆうことは先に設定しておかないといけないよ情報】を効率よく知るにはどうしたらよいのでしょうか？     TIPS的な知識を得るのになにか有用なサイトや書籍・資格試験などあれば教えて頂きたいです。     　<br />（DX社員なら当たり前に知ってるでしょ？的知識を身に着けたい） | 私もPythonの初級者向けの書籍を数多く出しているので、環境準備のハードルの高さはよく理解しています。      <br />自分でChatGPTを操作して言えることとして、データ分析目的で必要なTIPSは「コメントの日本語化指示」と「グラフ日本語化ライブラリの導入」の2点だけです。     <br />あとは、すぐにでも自分のやりたい分析ができると考えて下さい。 |
| Q09  | きちんとしたコードレビューをする際に、自然言語の指示の間違いに気づけるか、プログラムコードの記述でデバッガなどを使って検証すべきかの難易度によって、プロンプトベースのコーディングでいいかどうかが変わるように思います。どちらでの検証の方が向いているかなど、コード生成の前に判断するための基準などありますでしょうか？ | 非常に難しいタスクに関するご質問です。    <br /> AIとのやりとりを定期的に有識者にレビューしてもらい、そこでプロンプトのロジックのあやまりを指摘してもらうことが現実的な方法と思います。 |
| Q10  | プログラミング初心者です。普段から学習にChatGPTを使っています。     　<br />ChatGPTに例題を作ってもらう、自分が作ったコードや考察を添削してもらう、用語について説明してもらう以外に有効な利用方法があればご教授ください。 | このような会話的なやりかたでうまくいかないのは、体系的な理解が不十分になる点です。     <br />そこで、何か標準的な教科書を1つ決めて、「教科書の勉強をAIを家庭教師に実施する」アプローチを推奨します。    <br /> 手前味噌ではありますが、拙著「最短コースでわかる  Pythonプログラミングとデータ分析」はこの目的で最適な教科書と思っていますので、是非お試し下さい。 |
| Q11  | データサイエンティストとして、これから生成AIより優位な価値を提供できる人材になるために学ぶべき/大切にすべきスキルや領域はどのようなものがあると考えてますか？AI使ったモデル構築ツールのスキルor  pythonスキルでいうとどちらが優先度高いと考えられてますか？ | ご質問いただいた2つの領域はどちらも生成AIの得意領域であり、この領域でAIと張り合おうとするのは、今後、有効な方策ではないと思います。     <br />それよりも、「問いを立てる力」をつけることに注力していただくのがいいかと思います。 |
| Q12  | 儲かるデータ分析とは、一言でいうとどんなことでしょうか。本のPRでいいのですが。 | デモでご紹介した「クラスタリング」や「営業成約予測」など、ビジネスですぐに使えるユースケースを紹介し、今までデータ分析とは縁が遠かった方にもデータ分析を活用していただくようなところを目標とした書籍です |
| Q13  | タイタニック以外に、赤石さんがオススメの学習用のコンペは何かありますか？ | 書籍の4章から8章はすべて公開データセットを題材とした分析です。このあたりを一通り理解いただくと、「データ分析でできること」のイメージを持てるようになるかと思います。 |
| Q14  | データ分析を実施する中で、各生成AIを利用することでのデータ漏えいリスク（open  AI側にデータを閲覧される等）はありますか？ | opne  AIのアカウント設定で特定のフラグをセットしておくと、分析用にアップしたデータを再利用しないルールです。     しかし、このopen AIの言い分を100%信用できるかという点はあります。     <br />会社ごとに、データ漏洩防止のためのポリシーは定めていると思うので、必ずそのルールには従うようにして下さい。 |
| Q15  | 5章p.155 生成コード例5-5-3を知りたいです                     | 参考までに生成コード例5-5-3を示します。<br/># クラスタ単位での平均を計算（チャネルと地域を除外）<br/>df_cluster = df.groupby('クラスタ')[['生鮮食品', '牛乳', '食料品', '冷凍食品', '洗剤・紙類', 'デリカ']].mean()<br/># 小数第一位で四捨五入<br/>df_cluster = df_cluster.round(1)<br/><br/># 計算結果を表示<br/>df_cluster |



[メインページに戻る](../README.md)
